0. Vizwiz

   - understand the time

     - February: challenge submissions announced
     - Friday, April 24 [5:59pm Central Standard Time]: extended abstracts due
     - Monday, May 4 [5:59pm Central Standard Time]: notification to authors about decisions for extended abstracts
     - Friday, May 15 [5:59pm Central Standard Time]: challenge submissions due
     - Sunday, June 14: all-day workshop

   - understand the data

     [official paper](https://arxiv.org/pdf/2002.08565.pdf)

   - understand the evaluation

     [CIDEr](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.pdf)

     

1. Read papers, what are the current state-of-the-art

   - related researches

     [Deep Visual-Semantic Alignments](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)

     https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html

     https://github.com/karpathy/neuraltalk2

     [Baby talk](http://www.tamaraberg.com/papers/generation_cvpr11.pdf)

     [Midge](https://www.aclweb.org/anthology/W12-1523.pdf)

- past winners - past tasks are different - visual question answering 

  [Bilinear attention networks](https://bi.snu.ac.kr/Publications/Conferences/International/ECCV2018_Workshop_VizWiz_JHKim.pdf)

  [Contextualized Bilinear Attention](https://bi.snu.ac.kr/Publications/Conferences/International/ECCV2018_Workshop_VizWiz_GCKang.pdf)

  

- available models

- hardware requirement

1. Formulate a plan
   - baseline system
   - existing solution
     - https://github.com/karpathy/neuraltalk2
     - https://ai.googleblog.com/2016/09/show-and-tell-image-captioning-open.html
   - new solution
   - external data resource
2. Result generating





- slack
- share doc
- github repo